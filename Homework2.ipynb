{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqrhyv4Jb586uTJtyv3Doz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrisontg57/NLP_Spring_2021/blob/main/Homework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx7ug1RQsx0-"
      },
      "source": [
        "\r\n",
        "Tim Harrison ID: 002-24-5948"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3FzgGZvUDsE",
        "outputId": "7060ddee-7445-44e4-85ca-27dd7834d5df"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02_dD8v7syzO"
      },
      "source": [
        "Problem 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "JSQkTI19s0Ow",
        "outputId": "2c42390d-445a-422d-9faa-e00f6659b37e"
      },
      "source": [
        "import re\r\n",
        "import nltk\r\n",
        "import pandas as pd\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "play_names = [\"a-midsummer-nights-dream\",\"alls-well-that-ends-well\",\"antony-and-cleopatra\",\"as-you-like-it\",\"coriolanus\",\"cymbeline\",\"hamlet\",\"henry-iv-part-1\",\"henry-iv-part-2\",\"henry-v\",\"henry-vi-part-1\",\"henry-vi-part-2\",\"henry-vi-part-3\",\"henry-viii\",\"julius-caesar\"]\r\n",
        "play_strings = []\r\n",
        "\r\n",
        "for title in play_names:\r\n",
        "  with open('/content/'+title+'_TXT_FolgerShakespeare.txt', 'r') as file:\r\n",
        "      d = file.read().replace('\\n', ' ')\r\n",
        "      play_strings.append(d)\r\n",
        "\r\n",
        "#print(len(play_strings))\r\n",
        "\r\n",
        "Tfidf_vect = TfidfVectorizer()\r\n",
        "vector_matrix = Tfidf_vect.fit_transform(play_strings)\r\n",
        "\r\n",
        "cosine_similarity_matrix = cosine_similarity(vector_matrix)\r\n",
        "#print(cosine_similarity_matrix)\r\n",
        "pd.DataFrame(data=cosine_similarity_matrix,index=play_names,columns=play_names)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a-midsummer-nights-dream</th>\n",
              "      <th>alls-well-that-ends-well</th>\n",
              "      <th>antony-and-cleopatra</th>\n",
              "      <th>as-you-like-it</th>\n",
              "      <th>coriolanus</th>\n",
              "      <th>cymbeline</th>\n",
              "      <th>hamlet</th>\n",
              "      <th>henry-iv-part-1</th>\n",
              "      <th>henry-iv-part-2</th>\n",
              "      <th>henry-v</th>\n",
              "      <th>henry-vi-part-1</th>\n",
              "      <th>henry-vi-part-2</th>\n",
              "      <th>henry-vi-part-3</th>\n",
              "      <th>henry-viii</th>\n",
              "      <th>julius-caesar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>a-midsummer-nights-dream</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.721492</td>\n",
              "      <td>0.649114</td>\n",
              "      <td>0.665538</td>\n",
              "      <td>0.688681</td>\n",
              "      <td>0.718656</td>\n",
              "      <td>0.677110</td>\n",
              "      <td>0.760838</td>\n",
              "      <td>0.768654</td>\n",
              "      <td>0.771913</td>\n",
              "      <td>0.743208</td>\n",
              "      <td>0.760478</td>\n",
              "      <td>0.719175</td>\n",
              "      <td>0.769703</td>\n",
              "      <td>0.655901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alls-well-that-ends-well</th>\n",
              "      <td>0.721492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.683257</td>\n",
              "      <td>0.695009</td>\n",
              "      <td>0.734359</td>\n",
              "      <td>0.762164</td>\n",
              "      <td>0.716698</td>\n",
              "      <td>0.783370</td>\n",
              "      <td>0.805714</td>\n",
              "      <td>0.798095</td>\n",
              "      <td>0.768704</td>\n",
              "      <td>0.782100</td>\n",
              "      <td>0.740178</td>\n",
              "      <td>0.829208</td>\n",
              "      <td>0.680604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>antony-and-cleopatra</th>\n",
              "      <td>0.649114</td>\n",
              "      <td>0.683257</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.610599</td>\n",
              "      <td>0.659735</td>\n",
              "      <td>0.678471</td>\n",
              "      <td>0.630071</td>\n",
              "      <td>0.700240</td>\n",
              "      <td>0.713721</td>\n",
              "      <td>0.709946</td>\n",
              "      <td>0.686683</td>\n",
              "      <td>0.702209</td>\n",
              "      <td>0.664561</td>\n",
              "      <td>0.723164</td>\n",
              "      <td>0.711354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>as-you-like-it</th>\n",
              "      <td>0.665538</td>\n",
              "      <td>0.695009</td>\n",
              "      <td>0.610599</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.661847</td>\n",
              "      <td>0.685904</td>\n",
              "      <td>0.636910</td>\n",
              "      <td>0.710177</td>\n",
              "      <td>0.724722</td>\n",
              "      <td>0.717780</td>\n",
              "      <td>0.687543</td>\n",
              "      <td>0.701415</td>\n",
              "      <td>0.660897</td>\n",
              "      <td>0.732286</td>\n",
              "      <td>0.621824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>coriolanus</th>\n",
              "      <td>0.688681</td>\n",
              "      <td>0.734359</td>\n",
              "      <td>0.659735</td>\n",
              "      <td>0.661847</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.727801</td>\n",
              "      <td>0.675620</td>\n",
              "      <td>0.745189</td>\n",
              "      <td>0.768706</td>\n",
              "      <td>0.762026</td>\n",
              "      <td>0.725305</td>\n",
              "      <td>0.741927</td>\n",
              "      <td>0.700714</td>\n",
              "      <td>0.788711</td>\n",
              "      <td>0.691778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cymbeline</th>\n",
              "      <td>0.718656</td>\n",
              "      <td>0.762164</td>\n",
              "      <td>0.678471</td>\n",
              "      <td>0.685904</td>\n",
              "      <td>0.727801</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.701331</td>\n",
              "      <td>0.776533</td>\n",
              "      <td>0.788278</td>\n",
              "      <td>0.781753</td>\n",
              "      <td>0.758870</td>\n",
              "      <td>0.775450</td>\n",
              "      <td>0.734600</td>\n",
              "      <td>0.807625</td>\n",
              "      <td>0.675647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hamlet</th>\n",
              "      <td>0.677110</td>\n",
              "      <td>0.716698</td>\n",
              "      <td>0.630071</td>\n",
              "      <td>0.636910</td>\n",
              "      <td>0.675620</td>\n",
              "      <td>0.701331</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.738146</td>\n",
              "      <td>0.753435</td>\n",
              "      <td>0.756079</td>\n",
              "      <td>0.720225</td>\n",
              "      <td>0.740773</td>\n",
              "      <td>0.702772</td>\n",
              "      <td>0.768048</td>\n",
              "      <td>0.632892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>henry-iv-part-1</th>\n",
              "      <td>0.760838</td>\n",
              "      <td>0.783370</td>\n",
              "      <td>0.700240</td>\n",
              "      <td>0.710177</td>\n",
              "      <td>0.745189</td>\n",
              "      <td>0.776533</td>\n",
              "      <td>0.738146</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.928976</td>\n",
              "      <td>0.862504</td>\n",
              "      <td>0.824907</td>\n",
              "      <td>0.842985</td>\n",
              "      <td>0.798493</td>\n",
              "      <td>0.843569</td>\n",
              "      <td>0.707524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>henry-iv-part-2</th>\n",
              "      <td>0.768654</td>\n",
              "      <td>0.805714</td>\n",
              "      <td>0.713721</td>\n",
              "      <td>0.724722</td>\n",
              "      <td>0.768706</td>\n",
              "      <td>0.788278</td>\n",
              "      <td>0.753435</td>\n",
              "      <td>0.928976</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.879595</td>\n",
              "      <td>0.828876</td>\n",
              "      <td>0.852334</td>\n",
              "      <td>0.810499</td>\n",
              "      <td>0.870072</td>\n",
              "      <td>0.718555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>henry-v</th>\n",
              "      <td>0.771913</td>\n",
              "      <td>0.798095</td>\n",
              "      <td>0.709946</td>\n",
              "      <td>0.717780</td>\n",
              "      <td>0.762026</td>\n",
              "      <td>0.781753</td>\n",
              "      <td>0.756079</td>\n",
              "      <td>0.862504</td>\n",
              "      <td>0.879595</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.865623</td>\n",
              "      <td>0.881874</td>\n",
              "      <td>0.838788</td>\n",
              "      <td>0.876847</td>\n",
              "      <td>0.717541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>henry-vi-part-1</th>\n",
              "      <td>0.743208</td>\n",
              "      <td>0.768704</td>\n",
              "      <td>0.686683</td>\n",
              "      <td>0.687543</td>\n",
              "      <td>0.725305</td>\n",
              "      <td>0.758870</td>\n",
              "      <td>0.720225</td>\n",
              "      <td>0.824907</td>\n",
              "      <td>0.828876</td>\n",
              "      <td>0.865623</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.890848</td>\n",
              "      <td>0.835915</td>\n",
              "      <td>0.832728</td>\n",
              "      <td>0.684078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>henry-vi-part-2</th>\n",
              "      <td>0.760478</td>\n",
              "      <td>0.782100</td>\n",
              "      <td>0.702209</td>\n",
              "      <td>0.701415</td>\n",
              "      <td>0.741927</td>\n",
              "      <td>0.775450</td>\n",
              "      <td>0.740773</td>\n",
              "      <td>0.842985</td>\n",
              "      <td>0.852334</td>\n",
              "      <td>0.881874</td>\n",
              "      <td>0.890848</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.889320</td>\n",
              "      <td>0.870002</td>\n",
              "      <td>0.699187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>henry-vi-part-3</th>\n",
              "      <td>0.719175</td>\n",
              "      <td>0.740178</td>\n",
              "      <td>0.664561</td>\n",
              "      <td>0.660897</td>\n",
              "      <td>0.700714</td>\n",
              "      <td>0.734600</td>\n",
              "      <td>0.702772</td>\n",
              "      <td>0.798493</td>\n",
              "      <td>0.810499</td>\n",
              "      <td>0.838788</td>\n",
              "      <td>0.835915</td>\n",
              "      <td>0.889320</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.810753</td>\n",
              "      <td>0.661132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>henry-viii</th>\n",
              "      <td>0.769703</td>\n",
              "      <td>0.829208</td>\n",
              "      <td>0.723164</td>\n",
              "      <td>0.732286</td>\n",
              "      <td>0.788711</td>\n",
              "      <td>0.807625</td>\n",
              "      <td>0.768048</td>\n",
              "      <td>0.843569</td>\n",
              "      <td>0.870072</td>\n",
              "      <td>0.876847</td>\n",
              "      <td>0.832728</td>\n",
              "      <td>0.870002</td>\n",
              "      <td>0.810753</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.722450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>julius-caesar</th>\n",
              "      <td>0.655901</td>\n",
              "      <td>0.680604</td>\n",
              "      <td>0.711354</td>\n",
              "      <td>0.621824</td>\n",
              "      <td>0.691778</td>\n",
              "      <td>0.675647</td>\n",
              "      <td>0.632892</td>\n",
              "      <td>0.707524</td>\n",
              "      <td>0.718555</td>\n",
              "      <td>0.717541</td>\n",
              "      <td>0.684078</td>\n",
              "      <td>0.699187</td>\n",
              "      <td>0.661132</td>\n",
              "      <td>0.722450</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          a-midsummer-nights-dream  ...  julius-caesar\n",
              "a-midsummer-nights-dream                  1.000000  ...       0.655901\n",
              "alls-well-that-ends-well                  0.721492  ...       0.680604\n",
              "antony-and-cleopatra                      0.649114  ...       0.711354\n",
              "as-you-like-it                            0.665538  ...       0.621824\n",
              "coriolanus                                0.688681  ...       0.691778\n",
              "cymbeline                                 0.718656  ...       0.675647\n",
              "hamlet                                    0.677110  ...       0.632892\n",
              "henry-iv-part-1                           0.760838  ...       0.707524\n",
              "henry-iv-part-2                           0.768654  ...       0.718555\n",
              "henry-v                                   0.771913  ...       0.717541\n",
              "henry-vi-part-1                           0.743208  ...       0.684078\n",
              "henry-vi-part-2                           0.760478  ...       0.699187\n",
              "henry-vi-part-3                           0.719175  ...       0.661132\n",
              "henry-viii                                0.769703  ...       0.722450\n",
              "julius-caesar                             0.655901  ...       1.000000\n",
              "\n",
              "[15 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_P-Rxyxy2kI"
      },
      "source": [
        "Problem 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EmaDfqHy34g",
        "outputId": "44deb0e6-e873-438e-82eb-50d9399a6126"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def top_n(m,n):\r\n",
        "  li = []\r\n",
        "  i = np.identity(len(play_names))\r\n",
        "  df =  pd.DataFrame(data=m,index=play_names,columns=play_names)\r\n",
        "  ident = pd.DataFrame(data=i,index=play_names,columns=play_names)\r\n",
        "  no_ones = df.sub(ident)\r\n",
        "  for k in range(n):\r\n",
        "    top = np.argmax(no_ones)\r\n",
        "    li.append((play_names[int(top/len(play_names))],play_names[top%len(play_names)]))\r\n",
        "    no_ones.at[play_names[int(top/len(play_names))],play_names[top%len(play_names)]] = 0\r\n",
        "    no_ones.at[play_names[top%len(play_names)],play_names[int(top/len(play_names))]] = 0\r\n",
        "  return li\r\n",
        "top_n(cosine_similarity_matrix,10)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('henry-iv-part-1', 'henry-iv-part-2'),\n",
              " ('henry-vi-part-1', 'henry-vi-part-2'),\n",
              " ('henry-vi-part-2', 'henry-vi-part-3'),\n",
              " ('henry-v', 'henry-vi-part-2'),\n",
              " ('henry-iv-part-2', 'henry-v'),\n",
              " ('henry-v', 'henry-viii'),\n",
              " ('henry-iv-part-2', 'henry-viii'),\n",
              " ('henry-vi-part-2', 'henry-viii'),\n",
              " ('henry-v', 'henry-vi-part-1'),\n",
              " ('henry-iv-part-1', 'henry-v')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WK0e3jL5pqk"
      },
      "source": [
        "Problem 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Qs8oeh5rGH",
        "outputId": "facbc3b8-d363-46ff-f63d-e65a42408124"
      },
      "source": [
        "import nltk\r\n",
        "from nltk import bigrams, trigrams\r\n",
        "from collections import Counter, defaultdict\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "\r\n",
        "plays = []\r\n",
        "\r\n",
        "for title in play_names:\r\n",
        "  with open('/content/'+title+'_TXT_FolgerShakespeare.txt', 'r') as file:\r\n",
        "    lines = [line.rstrip() for line in file]\r\n",
        "    #remove non letters except '\r\n",
        "    lines = [re.sub(r'[^a-zA-Z0-9_\\']',' ',line) for line in lines]\r\n",
        "    #Remove Capitalized words (ie character names)\r\n",
        "    lines = [re.sub(r'[A-Z][A-Z]+','',line) for line in lines]\r\n",
        "    plays.extend(lines)\r\n",
        "#print(plays)\r\n",
        "\r\n",
        "model_t = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "for sentence in plays:\r\n",
        "    #print(nltk.word_tokenize(sentence))\r\n",
        "    for w1, w2, w3 in trigrams(nltk.word_tokenize(sentence), pad_right=True, pad_left=True):\r\n",
        "        model_t[(w1, w2)][w3] += 1\r\n",
        "\r\n",
        "for w1_w2 in model_t:\r\n",
        "    total_count = float(sum(model_t[w1_w2].values()))\r\n",
        "    for w3 in model_t[w1_w2]:\r\n",
        "        model_t[w1_w2][w3] /= total_count\r\n",
        "\r\n",
        "#dict(model_t[\"the\",\"time\"])\r\n",
        "\r\n",
        "model_b = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "for sentence in plays:\r\n",
        "    #print(nltk.word_tokenize(sentence))\r\n",
        "    for w1, w2 in bigrams(nltk.word_tokenize(sentence), pad_right=True, pad_left=True):\r\n",
        "        model_b[(w1)][w2] += 1\r\n",
        "\r\n",
        "for w1 in model_b:\r\n",
        "    total_count = float(sum(model_b[w1].values()))\r\n",
        "    for w2 in model_b[w1]:\r\n",
        "        model_b[w1][w2] /= total_count\r\n",
        "\r\n",
        "#dict(model_b[\"dog\"])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCl882IyPCoL"
      },
      "source": [
        "Problem 4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRXkY0v9PEBV",
        "outputId": "c3af1c03-8bff-4377-d0fe-375896b358af"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "# starting words\r\n",
        "\r\n",
        "def sentence_generator(model, start_terms, number_sentences):\r\n",
        "  text = start_terms[:]\r\n",
        "  new_sentences = []\r\n",
        "  if model == \"trigram\":\r\n",
        "    for x in range(number_sentences):\r\n",
        "        sentence_finished = False\r\n",
        "        while not sentence_finished:\r\n",
        "          # select a random probability threshold  \r\n",
        "          r = random.random()\r\n",
        "          accumulator = .0\r\n",
        "          for word in model_t[tuple(text[-2:])].keys():\r\n",
        "              accumulator += model_t[tuple(text[-2:])][word]\r\n",
        "              # select words that are above the probability threshold\r\n",
        "              if accumulator >= r:\r\n",
        "                  text.append(word)\r\n",
        "                  break\r\n",
        "          if text[-2:] == [None, None]:\r\n",
        "              sentence_finished = True\r\n",
        "        new_sentences.append(' '.join([t for t in text if t]))\r\n",
        "        text = start_terms[:]\r\n",
        "\r\n",
        "  elif model == \"bigram\":\r\n",
        "    for x in range(number_sentences):\r\n",
        "        sentence_finished = False\r\n",
        "        while not sentence_finished:\r\n",
        "          # select a random probability threshold  \r\n",
        "          r = random.random()\r\n",
        "          accumulator = .0\r\n",
        "          for word in model_b[text[-1]].keys():\r\n",
        "              accumulator += model_b[text[-1]][word]\r\n",
        "              # select words that are above the probability threshold\r\n",
        "              if accumulator >= r:\r\n",
        "                  text.append(word)\r\n",
        "                  break\r\n",
        "          if text[-2:] == [None, None]:\r\n",
        "              sentence_finished = True\r\n",
        "        new_sentences.append(' '.join([t for t in text if t]))\r\n",
        "        text = start_terms[:]\r\n",
        "  return new_sentences\r\n",
        "\r\n",
        "print(sentence_generator(\"bigram\",[\"come\"],10))\r\n",
        "print(sentence_generator(\"trigram\",[\"as\", \"much\"],5))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['come to the walls Pucelle now lady nigh Enter a poor soul In private malice of rebellion', \"come what prevention He is the world see Titan and much and if I would fain shut us what hope sir are my eye and that he is gone The ragged'st hour of the like larks\", 'come to Buckingham on And Britons cold and read it for men I sent lovers love Rosalind these wars', 'come you I am hushed with the spirit will go in the writs go But I grow dull If it for the law thou live Is your places But take their knavery will look you would not find Tut I will blow away to break his good cousin Shallow performs', \"come She shall be For I can that no I By the top proud Where now Cominius head on you prove an exact command the French lack some more trust thee poetical with joy but reckless shepherd men According to unthink your sickness Come bring him not by him hither to his courtesy Be theme so true gentleness my fair and duty And thou so buried out Sennet They enter Your Majesty let 's means this marriage move prayers to choose Yes forsooth Of no pastime Dies in unpaid for strength denied\", \"come not make we are they are honest Behold and the fatal and no skill In every flaw Shall 's Hecuba fellows Come good my tongue most expert gentleman No noble Caesar 's eye of your land which hath not call it be resolved\", \"come Master Shallow Ay my behalf slaves how to make a crow cock and you lady Shall this they shall inherit too long of the four times treble woe Why 't\", 'come Our content Provide your Grace and forts To his beggar wouldst grieve him', \"come against your content Let me Caius and Bullcalf o ' head below King with thy head\", 'come not be mine arm']\n",
            "['as much as the ass in compound with the happiest terms I have wept for I think to draw mine honor I dare be bold with time and oft have hindered oft', 'as much as from a dying man receive as certain as I did not seduce', 'as much as his', 'as much', 'as much as we are and that should learn']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}