{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exam1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxgrnjw6jBl85nddvt2wgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrisontg57/NLP_Spring_2021/blob/main/Exam1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNgJZ425e3QW"
      },
      "source": [
        "Tim Harrison\r\n",
        "Exam 1\r\n",
        "Student ID: 002-24-5948"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvyOD7Wqo90L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "2de4954a-2c0e-4b21-e722-51377053c45e"
      },
      "source": [
        "#Handling file imports here and creating dataframes\r\n",
        "from os import walk\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "random.seed(12345)\r\n",
        "\r\n",
        "_, _, filenames_neg = next(walk(\"TRAINING/negative\"))\r\n",
        "_, _, filenames_pos = next(walk(\"TRAINING/positive\"))\r\n",
        "#print(filenames_neg[0:10])\r\n",
        "ones = [1] * len(filenames_pos)\r\n",
        "zeroes = [0] * len(filenames_neg)\r\n",
        "pos_txt = []\r\n",
        "for name in filenames_pos:\r\n",
        "  with open('/content/TRAINING/positive/'+name, 'r') as file:\r\n",
        "      d = file.read().replace('\\n', ' ')\r\n",
        "      pos_txt.append(d)\r\n",
        "df_pos = pd.DataFrame(data={'text': pos_txt, 'sentiment': ones})\r\n",
        "neg_txt = []\r\n",
        "for name in filenames_neg:\r\n",
        "  with open('/content/TRAINING/negative/'+name, 'r') as file:\r\n",
        "      d = file.read().replace('\\n', ' ')\r\n",
        "      neg_txt.append(d)\r\n",
        "df_neg = pd.DataFrame(data={'text': neg_txt, 'sentiment': zeroes})\r\n",
        "\r\n",
        "#df_neg.sample(frac=0.75,random_state=12345)\r\n",
        "\r\n",
        "data = df_pos.append(df_neg)\r\n",
        "#data.sample(frac=0.75,random_state=12345)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>Okay, now what the hell is this supposed to be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>The only reason I wanted to see this was becau...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>There are few comedies like this, where almost...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>This is a very good movie. Do you want to know...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>\"Margaritas and Cock...\"&lt;br /&gt;&lt;br /&gt;This treme...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1527</th>\n",
              "      <td>My choice for greatest movie ever used to be L...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>The Haunted World of Edward D. Wood, Jr. isn't...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>Perhaps the funniest 'backstage at Hollywood' ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>This is a powerful documentary about domestic ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>As with a bunch of guys at school we must give...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2182 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  sentiment\n",
              "189   Okay, now what the hell is this supposed to be...          0\n",
              "1498  The only reason I wanted to see this was becau...          1\n",
              "826   There are few comedies like this, where almost...          1\n",
              "850   This is a very good movie. Do you want to know...          1\n",
              "748   \"Margaritas and Cock...\"<br /><br />This treme...          1\n",
              "...                                                 ...        ...\n",
              "1527  My choice for greatest movie ever used to be L...          1\n",
              "1370  The Haunted World of Edward D. Wood, Jr. isn't...          1\n",
              "515   Perhaps the funniest 'backstage at Hollywood' ...          1\n",
              "883   This is a powerful documentary about domestic ...          1\n",
              "867   As with a bunch of guys at school we must give...          1\n",
              "\n",
              "[2182 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3aUU1t6e9gV"
      },
      "source": [
        "Question 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7q43tIOe_su"
      },
      "source": [
        "import pandas as pd\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.linear_model import Perceptron\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.pipeline import make_pipeline, FeatureUnion\r\n",
        "\r\n",
        "def create_model(alg_name, vectorization, train):\r\n",
        "  if alg_name == \"naive_bayes\":\r\n",
        "    learn = MultinomialNB()\r\n",
        "  elif alg_name == \"perceptron\":\r\n",
        "    learn = Perceptron()\r\n",
        "  elif alg_name == \"logistic_regression\":\r\n",
        "    learn = LogisticRegression()\r\n",
        "  else:\r\n",
        "    raise NameError('incorrect algorithm name')\r\n",
        "\r\n",
        "  if vectorization == \"tfidf\":\r\n",
        "    vect = TfidfVectorizer()\r\n",
        "  elif vectorization == \"bag_of_words\":\r\n",
        "    vect = CountVectorizer()\r\n",
        "  elif vectorization == \"both\":\r\n",
        "    vect = FeatureUnion([(\"tfidf\", TfidfVectorizer()), (\"bag_of_words\", CountVectorizer())])\r\n",
        "  else:\r\n",
        "    raise NameError('incorrect vectorization name')\r\n",
        "  \r\n",
        "  model = make_pipeline(vect, learn)\r\n",
        "  model.fit(train.text, train.sentiment)\r\n",
        "  return model\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4lZWVeqyI85"
      },
      "source": [
        "Question 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHbe1qatyKDa",
        "outputId": "f6a20475-e285-4ef0-e94c-80c7e279a08c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train_a, test_a = train_test_split(data, test_size=0.25,random_state=12345)\r\n",
        "model_a = create_model(\"naive_bayes\",\"both\",train_a)\r\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('featureunion',\n",
              "                 FeatureUnion(n_jobs=None,\n",
              "                              transformer_list=[('tfidf',\n",
              "                                                 TfidfVectorizer(analyzer='word',\n",
              "                                                                 binary=False,\n",
              "                                                                 decode_error='strict',\n",
              "                                                                 dtype=<class 'numpy.float64'>,\n",
              "                                                                 encoding='utf-8',\n",
              "                                                                 input='content',\n",
              "                                                                 lowercase=True,\n",
              "                                                                 max_df=1.0,\n",
              "                                                                 max_features=None,\n",
              "                                                                 min_df=1,\n",
              "                                                                 ngram_range=(1,\n",
              "                                                                              1),\n",
              "                                                                 norm='l2',\n",
              "                                                                 preprocessor=None,\n",
              "                                                                 smooth_idf=True,\n",
              "                                                                 stop_words...\n",
              "                                                                 encoding='utf-8',\n",
              "                                                                 input='content',\n",
              "                                                                 lowercase=True,\n",
              "                                                                 max_df=1.0,\n",
              "                                                                 max_features=None,\n",
              "                                                                 min_df=1,\n",
              "                                                                 ngram_range=(1,\n",
              "                                                                              1),\n",
              "                                                                 preprocessor=None,\n",
              "                                                                 stop_words=None,\n",
              "                                                                 strip_accents=None,\n",
              "                                                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                                                 tokenizer=None,\n",
              "                                                                 vocabulary=None))],\n",
              "                              transformer_weights=None, verbose=False)),\n",
              "                ('multinomialnb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyYF9e4U2omt"
      },
      "source": [
        "Question 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Qbb-th8M2qOk",
        "outputId": "544fe81a-bb4d-40de-c05d-06a0cb0d8ab4"
      },
      "source": [
        "labels = model_a.predict(test_a.text)\r\n",
        "pd.DataFrame(data={'text': test_a.text, 'true_sentiment': test_a.sentiment, 'Predicted_sentiment': labels})"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>true_sentiment</th>\n",
              "      <th>Predicted_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>Okay, now what the hell is this supposed to be...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>The only reason I wanted to see this was becau...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>There are few comedies like this, where almost...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>This is a very good movie. Do you want to know...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>\"Margaritas and Cock...\"&lt;br /&gt;&lt;br /&gt;This treme...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1313</th>\n",
              "      <td>I saw this movie when it first came out. It wa...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>I absolutely loved this movie. I am not even s...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1172</th>\n",
              "      <td>PERHAPS in an attempt to find another \"Hot Pro...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>I cannot believe this woodenly written and dir...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1529</th>\n",
              "      <td>EL MAR is a tough, stark, utterly brilliant, b...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>728 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...  Predicted_sentiment\n",
              "189   Okay, now what the hell is this supposed to be...  ...                    0\n",
              "1498  The only reason I wanted to see this was becau...  ...                    0\n",
              "826   There are few comedies like this, where almost...  ...                    1\n",
              "850   This is a very good movie. Do you want to know...  ...                    1\n",
              "748   \"Margaritas and Cock...\"<br /><br />This treme...  ...                    1\n",
              "...                                                 ...  ...                  ...\n",
              "1313  I saw this movie when it first came out. It wa...  ...                    1\n",
              "381   I absolutely loved this movie. I am not even s...  ...                    1\n",
              "1172  PERHAPS in an attempt to find another \"Hot Pro...  ...                    1\n",
              "708   I cannot believe this woodenly written and dir...  ...                    0\n",
              "1529  EL MAR is a tough, stark, utterly brilliant, b...  ...                    1\n",
              "\n",
              "[728 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}