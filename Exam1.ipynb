{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exam1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPry0pxFkFtfOr3MtK05IfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrisontg57/NLP_Spring_2021/blob/main/Exam1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNgJZ425e3QW"
      },
      "source": [
        "Tim Harrison\r\n",
        "Exam 1\r\n",
        "Student ID: 002-24-5948"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvyOD7Wqo90L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "2de4954a-2c0e-4b21-e722-51377053c45e"
      },
      "source": [
        "#Handling file imports here and creating dataframes\r\n",
        "from os import walk\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "random.seed(12345)\r\n",
        "\r\n",
        "_, _, filenames_neg = next(walk(\"TRAINING/negative\"))\r\n",
        "_, _, filenames_pos = next(walk(\"TRAINING/positive\"))\r\n",
        "#print(filenames_neg[0:10])\r\n",
        "ones = [1] * len(filenames_pos)\r\n",
        "zeroes = [0] * len(filenames_neg)\r\n",
        "pos_txt = []\r\n",
        "for name in filenames_pos:\r\n",
        "  with open('/content/TRAINING/positive/'+name, 'r') as file:\r\n",
        "      d = file.read().replace('\\n', ' ')\r\n",
        "      pos_txt.append(d)\r\n",
        "df_pos = pd.DataFrame(data={'text': pos_txt, 'sentiment': ones})\r\n",
        "neg_txt = []\r\n",
        "for name in filenames_neg:\r\n",
        "  with open('/content/TRAINING/negative/'+name, 'r') as file:\r\n",
        "      d = file.read().replace('\\n', ' ')\r\n",
        "      neg_txt.append(d)\r\n",
        "df_neg = pd.DataFrame(data={'text': neg_txt, 'sentiment': zeroes})\r\n",
        "\r\n",
        "#df_neg.sample(frac=0.75,random_state=12345)\r\n",
        "\r\n",
        "data = df_pos.append(df_neg)\r\n",
        "#data.sample(frac=0.75,random_state=12345)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>Okay, now what the hell is this supposed to be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>The only reason I wanted to see this was becau...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>There are few comedies like this, where almost...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>This is a very good movie. Do you want to know...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>\"Margaritas and Cock...\"&lt;br /&gt;&lt;br /&gt;This treme...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1527</th>\n",
              "      <td>My choice for greatest movie ever used to be L...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>The Haunted World of Edward D. Wood, Jr. isn't...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>Perhaps the funniest 'backstage at Hollywood' ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>This is a powerful documentary about domestic ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>As with a bunch of guys at school we must give...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2182 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  sentiment\n",
              "189   Okay, now what the hell is this supposed to be...          0\n",
              "1498  The only reason I wanted to see this was becau...          1\n",
              "826   There are few comedies like this, where almost...          1\n",
              "850   This is a very good movie. Do you want to know...          1\n",
              "748   \"Margaritas and Cock...\"<br /><br />This treme...          1\n",
              "...                                                 ...        ...\n",
              "1527  My choice for greatest movie ever used to be L...          1\n",
              "1370  The Haunted World of Edward D. Wood, Jr. isn't...          1\n",
              "515   Perhaps the funniest 'backstage at Hollywood' ...          1\n",
              "883   This is a powerful documentary about domestic ...          1\n",
              "867   As with a bunch of guys at school we must give...          1\n",
              "\n",
              "[2182 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3aUU1t6e9gV"
      },
      "source": [
        "Question 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7q43tIOe_su"
      },
      "source": [
        "import pandas as pd\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.linear_model import Perceptron\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.pipeline import make_pipeline, FeatureUnion\r\n",
        "\r\n",
        "def create_model(alg_name, vectorization, train):\r\n",
        "  if alg_name == \"naive_bayes\":\r\n",
        "    learn = MultinomialNB()\r\n",
        "  elif alg_name == \"perceptron\":\r\n",
        "    learn = Perceptron()\r\n",
        "  elif alg_name == \"logistic_regression\":\r\n",
        "    learn = LogisticRegression()\r\n",
        "  elif alg_name == \"random_forest\":\r\n",
        "    learn = RandomForestClassifier()\r\n",
        "  elif alg_name == \"svm\":\r\n",
        "    learn = SVC()\r\n",
        "  else:\r\n",
        "    raise NameError('incorrect algorithm name')\r\n",
        "\r\n",
        "  if vectorization == \"tfidf\":\r\n",
        "    vect = TfidfVectorizer()\r\n",
        "  elif vectorization == \"bag_of_words\":\r\n",
        "    vect = CountVectorizer()\r\n",
        "  elif vectorization == \"both\":\r\n",
        "    vect = FeatureUnion([(\"tfidf\", TfidfVectorizer()), (\"bag_of_words\", CountVectorizer())])\r\n",
        "  else:\r\n",
        "    raise NameError('incorrect vectorization name')\r\n",
        "  \r\n",
        "  model = make_pipeline(vect, learn)\r\n",
        "  model.fit(train.text, train.sentiment)\r\n",
        "  return model\r\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4lZWVeqyI85"
      },
      "source": [
        "Question 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHbe1qatyKDa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train_a, test_a = train_test_split(data, test_size=0.25,random_state=12345)\r\n",
        "model_a = create_model(\"naive_bayes\",\"both\",train_a)\r\n",
        "\r\n",
        "train_b, test_b = train_test_split(data, test_size=0.30,random_state=12345)\r\n",
        "model_b = create_model(\"random_forest\",\"both\",train_b)\r\n",
        "\r\n",
        "train_c, test_c = train_test_split(data, test_size=0.40,random_state=12345)\r\n",
        "model_c = create_model(\"svm\",\"both\",train_c)\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyYF9e4U2omt"
      },
      "source": [
        "Question 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Qbb-th8M2qOk",
        "outputId": "f7950971-879a-4cc9-d167-626bf8a8c1f8"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\r\n",
        "labels_a = model_a.predict(test_a.text)\r\n",
        "results_a = pd.DataFrame(data={'text': test_a.text, 'true_sentiment': test_a.sentiment, 'modeled_sentiment': labels_a})\r\n",
        "\r\n",
        "scores_a = pd.DataFrame(data={'model': 'model_a', 'training_portion': [0.75], 'test_portion': [0.25], 'accuracy':accuracy_score(test_a.sentiment,labels_a),'precision':precision_score(test_a.sentiment,labels_a),'recall':recall_score(test_a.sentiment,labels_a),'f1-score':f1_score(test_a.sentiment,labels_a)})\r\n",
        "\r\n",
        "\r\n",
        "labels_b = model_b.predict(test_b.text)\r\n",
        "results_b = pd.DataFrame(data={'text': test_b.text, 'true_sentiment': test_b.sentiment, 'modeled_sentiment': labels_b})\r\n",
        "\r\n",
        "scores_b = pd.DataFrame(data={'model': 'model_b', 'training_portion': [0.70], 'test_portion': [0.30], 'accuracy':accuracy_score(test_b.sentiment,labels_b),'precision':precision_score(test_b.sentiment,labels_b),'recall':recall_score(test_b.sentiment,labels_b),'f1-score':f1_score(test_b.sentiment,labels_b)})\r\n",
        "\r\n",
        "\r\n",
        "labels_c = model_c.predict(test_c.text)\r\n",
        "results_c = pd.DataFrame(data={'text': test_c.text, 'true_sentiment': test_c.sentiment, 'modeled_sentiment': labels_c})\r\n",
        "\r\n",
        "scores_c = pd.DataFrame(data={'model': 'model_c', 'training_portion': [0.60], 'test_portion': [0.40], 'accuracy':accuracy_score(test_c.sentiment,labels_c),'precision':precision_score(test_c.sentiment,labels_c),'recall':recall_score(test_c.sentiment,labels_c),'f1-score':f1_score(test_c.sentiment,labels_c)})\r\n",
        "\r\n",
        "scores = scores_a.append(scores_b)\r\n",
        "scores = scores.append(scores_c)\r\n",
        "scores"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>training_portion</th>\n",
              "      <th>test_portion</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_a</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.861264</td>\n",
              "      <td>0.856828</td>\n",
              "      <td>0.915294</td>\n",
              "      <td>0.885097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_b</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.804124</td>\n",
              "      <td>0.780366</td>\n",
              "      <td>0.923228</td>\n",
              "      <td>0.845807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_c</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.743127</td>\n",
              "      <td>0.732034</td>\n",
              "      <td>0.883824</td>\n",
              "      <td>0.800799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model  training_portion  test_portion  ...  precision    recall  f1-score\n",
              "0  model_a              0.75          0.25  ...   0.856828  0.915294  0.885097\n",
              "0  model_b              0.70          0.30  ...   0.780366  0.923228  0.845807\n",
              "0  model_c              0.60          0.40  ...   0.732034  0.883824  0.800799\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}